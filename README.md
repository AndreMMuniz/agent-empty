# ü§ñ Agent Empty - Template LangGraph + RAG

Este √© um template de arquitetura robusta para cria√ß√£o de Agentes de IA Conversacional.
Ele utiliza **FastAPI** (Backend), **LangGraph** (Orquestra√ß√£o), **PostgreSQL/PGVector** (Mem√≥ria e Vetores) e **Streamlit** (Frontend de Teste).

## üèóÔ∏è Arquitetura

*   **API:** FastAPI (Async)
*   **C√©rebro:** LangGraph (Stateful Multi-turn)
*   **Mem√≥ria:** PostgreSQL (Checkpoints de conversa)
*   **RAG:** PGVector + LangChain Postgres
*   **Observabilidade:** Logs estruturados + LLM Judge + Dashboard Debugger
*   **Interface:** Streamlit

## üöÄ Como Iniciar

### 1. Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio**:
    ```bash
    git clone <seu-repo>
    cd agent-empty
    ```

2.  **Crie o ambiente virtual**:
    ```powershell
    # Windows
    python -m venv .venv
    .\.venv\Scripts\Activate
    ```
    ```bash
    # Linux/Mac
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Instale as depend√™ncias**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Suba o Banco de Dados (Docker)**:
    ```bash
    docker-compose up -d
    ```

5.  **Configure o `.env`**:
    Copie o arquivo de exemplo:
    ```bash
    cp .env.example .env
    ```
    *(Ajuste as vari√°veis se necess√°rio, como modelos do Ollama)*.

### 2. Ingest√£o de Dados (RAG)

Coloque seus arquivos (PDF, TXT, CSV, Imagens) na pasta `data/raw/` e execute:

```bash
python -m app.rag.ingestion
```
*Dica: O arquivo `sample.txt` j√° est√° l√° para teste.*

### 3. Executando o Agente

Voc√™ precisar√° de **dois terminais**:

**Terminal 1: Backend (API)**
```bash
python run.py
```
*Acesse a documenta√ß√£o da API em: http://localhost:8000/docs*

**Terminal 2: Frontend (Dashboard)**
```bash
streamlit run frontend/app.py
```
*O dashboard abrir√° automaticamente em: http://localhost:8501*

## üß™ Testes e Avalia√ß√£o

### Avalia√ß√£o Autom√°tica (LLM Judge)
Para rodar a bateria de testes contra o `golden_dataset.jsonl`:

1.  Certifique-se de ter o modelo `deepseek-r1:8b` (ou configure outro no `judge.py`):
    ```bash
    ollama pull deepseek-r1:8b
    ```
2.  Execute o juiz:
    ```bash
    python -m app.evaluation.judge
    ```
3.  Verifique o relat√≥rio em `data/datasets/evaluation_report.md`.

---
**Desenvolvido como Architecture Template para Agentes Inteligentes.**
